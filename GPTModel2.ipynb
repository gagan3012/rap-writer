{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPTModel2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8ZAedcnZJZdo7HELA5az/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gagan3012/rap-writer/blob/master/GPTModel2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVLvzuJTbN32"
      },
      "source": [
        "!pip install -U -q kaggle\r\n",
        "!mkdir ~/.kaggle\r\n",
        "!echo '{\"username\":\"gagan2000\",\"key\":\"73e5d9db85677b98fe016b25873727ec\"}' > ~/.kaggle/kaggle.json\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdfxsLWBf4cI",
        "outputId": "06c9fc69-490d-43c4-e51e-855a2cb0cda5"
      },
      "source": [
        "!kaggle datasets download -d rikdifos/rap-lyrics -p /content"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading rap-lyrics.zip to /content\n",
            "\r  0% 0.00/2.57M [00:00<?, ?B/s]\n",
            "\r100% 2.57M/2.57M [00:00<00:00, 84.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icDNGj2pf-BD",
        "outputId": "ab898981-287e-43d3-b708-dfcf79d98d24"
      },
      "source": [
        "!unzip /content/rap-lyrics.zip -d /content/rap"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/rap-lyrics.zip\n",
            "  inflating: /content/rap/ASAP Ant_lyrics.txt  \n",
            "  inflating: /content/rap/ASAP Rocky_lyrics.txt  \n",
            "  inflating: /content/rap/Action Bronson_lyrics.txt  \n",
            "  inflating: /content/rap/Andre 3000_lyrics.txt  \n",
            "  inflating: /content/rap/Bas_lyrics.txt  \n",
            "  inflating: /content/rap/Big L_lyrics.txt  \n",
            "  inflating: /content/rap/Chance The Rapper_lyrics.txt  \n",
            "  inflating: /content/rap/Childish Gambino_lyrics.txt  \n",
            "  inflating: /content/rap/Common_lyrics.txt  \n",
            "  inflating: /content/rap/CunninLynguists_lyrics.txt  \n",
            "  inflating: /content/rap/Deniro Farrar_lyrics.txt  \n",
            "  inflating: /content/rap/Drake_lyrics.txt  \n",
            "  inflating: /content/rap/Earl Sweatshirt_lyrics.txt  \n",
            "  inflating: /content/rap/Eazy-E_lyrics.txt  \n",
            "  inflating: /content/rap/Eminem_lyrics.txt  \n",
            "  inflating: /content/rap/Ice Cube_lyrics.txt  \n",
            "  inflating: /content/rap/Immortal Technique_lyrics.txt  \n",
            "  inflating: /content/rap/Isaiah Rashad_lyrics.txt  \n",
            "  inflating: /content/rap/J Cole_lyrics.txt  \n",
            "  inflating: /content/rap/Jay-z_lyrics.txt  \n",
            "  inflating: /content/rap/Joey Badass_lyrics.txt  \n",
            "  inflating: /content/rap/Kanye West_lyrics.txt  \n",
            "  inflating: /content/rap/Kendrick Lamar_lyrics.txt  \n",
            "  inflating: /content/rap/Lil Wayne_lyrics.txt  \n",
            "  inflating: /content/rap/Logic_lyrics.txt  \n",
            "  inflating: /content/rap/Lupe Fiasco_lyrics.txt  \n",
            "  inflating: /content/rap/Mac Miller_lyrics.txt  \n",
            "  inflating: /content/rap/Montana of 300_lyrics.txt  \n",
            "  inflating: /content/rap/NF_lyrics.txt  \n",
            "  inflating: /content/rap/Nas_lyrics.txt  \n",
            "  inflating: /content/rap/Pusha-T_lyrics.txt  \n",
            "  inflating: /content/rap/Royce Da 59_lyrics.txt  \n",
            "  inflating: /content/rap/Scarface_lyrics.txt  \n",
            "  inflating: /content/rap/Talib Kweli_lyrics.txt  \n",
            "  inflating: /content/rap/The Notorious BIG_lyrics.txt  \n",
            "  inflating: /content/rap/Tupac1_lyrics.txt  \n",
            "  inflating: /content/rap/Tupac2_lyrics.txt  \n",
            "  inflating: /content/rap/Tyler The Creator_lyrics.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLQRWD6WgE3y",
        "outputId": "0a3fbde6-8566-4378-808a-18083de48eb3"
      },
      "source": [
        "!pip install datasets\r\n",
        "!git clone https://github.com/huggingface/transformers\r\n",
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/12/5fd53adc5ba8a8d562b19f2c1c859547659e96b87a767cd52556538d205e/datasets-1.3.0-py3-none-any.whl (181kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 28.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 25.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 24.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61kB 26.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 71kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 18.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 102kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 133kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 143kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 174kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 18.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 44.8MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/93/7cb0755c62c36cdadc70c79a95681df685b52cbaf76c724facb6ecac3272/huggingface_hub-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.7.0)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, huggingface-hub, xxhash, datasets\n",
            "Successfully installed datasets-1.3.0 fsspec-0.8.7 huggingface-hub-0.0.2 xxhash-2.0.0\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 64820 (delta 16), reused 2 (delta 0), pack-reused 64779\u001b[K\n",
            "Receiving objects: 100% (64820/64820), 48.74 MiB | 29.55 MiB/s, done.\n",
            "Resolving deltas: 100% (45939/45939), done.\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 21.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.8MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=a23a57f602c1037b91ff9e6a880e43b40736eb7265d19f6ad955c54f9cd64d61\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2-YcqSagfMU"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import os\r\n",
        "import glob"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ne8PKWIh6jo"
      },
      "source": [
        "def getListOfFiles(dirName):\r\n",
        "    # create a list of file and sub directories \r\n",
        "    # names in the given directory \r\n",
        "    listOfFile = os.listdir(dirName)\r\n",
        "    allFiles = list()\r\n",
        "    # Iterate over all the entries\r\n",
        "    for entry in listOfFile:\r\n",
        "        # Create full path\r\n",
        "        fullPath = os.path.join(dirName, entry)\r\n",
        "        # If entry is a directory then get the list of files in this directory \r\n",
        "        if os.path.isdir(fullPath):\r\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\r\n",
        "        else:\r\n",
        "            allFiles.append(fullPath)\r\n",
        "                \r\n",
        "    return allFiles  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__rP2eW9hLba",
        "outputId": "6df17957-7eb0-4da3-a76b-ef870d189318"
      },
      "source": [
        "filenames = getListOfFiles('/content/rap')\r\n",
        "with open('/content/raplyrics.txt', 'w') as outfile:\r\n",
        "    for fname in filenames:\r\n",
        "        print(fname)\r\n",
        "        with open(fname, encoding='utf-8',errors='ignore') as infile:\r\n",
        "            for line in infile:\r\n",
        "                outfile.write(line)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rap/Eminem_lyrics.txt\n",
            "/content/rap/Tupac1_lyrics.txt\n",
            "/content/rap/Drake_lyrics.txt\n",
            "/content/rap/Big L_lyrics.txt\n",
            "/content/rap/Kanye West_lyrics.txt\n",
            "/content/rap/The Notorious BIG_lyrics.txt\n",
            "/content/rap/Eazy-E_lyrics.txt\n",
            "/content/rap/Royce Da 59_lyrics.txt\n",
            "/content/rap/Tupac2_lyrics.txt\n",
            "/content/rap/Earl Sweatshirt_lyrics.txt\n",
            "/content/rap/Logic_lyrics.txt\n",
            "/content/rap/NF_lyrics.txt\n",
            "/content/rap/Childish Gambino_lyrics.txt\n",
            "/content/rap/Jay-z_lyrics.txt\n",
            "/content/rap/Chance The Rapper_lyrics.txt\n",
            "/content/rap/Immortal Technique_lyrics.txt\n",
            "/content/rap/Joey Badass_lyrics.txt\n",
            "/content/rap/ASAP Rocky_lyrics.txt\n",
            "/content/rap/Ice Cube_lyrics.txt\n",
            "/content/rap/Tyler The Creator_lyrics.txt\n",
            "/content/rap/Nas_lyrics.txt\n",
            "/content/rap/Scarface_lyrics.txt\n",
            "/content/rap/Andre 3000_lyrics.txt\n",
            "/content/rap/Kendrick Lamar_lyrics.txt\n",
            "/content/rap/Action Bronson_lyrics.txt\n",
            "/content/rap/Mac Miller_lyrics.txt\n",
            "/content/rap/Montana of 300_lyrics.txt\n",
            "/content/rap/J Cole_lyrics.txt\n",
            "/content/rap/Lupe Fiasco_lyrics.txt\n",
            "/content/rap/Lil Wayne_lyrics.txt\n",
            "/content/rap/Talib Kweli_lyrics.txt\n",
            "/content/rap/Pusha-T_lyrics.txt\n",
            "/content/rap/Isaiah Rashad_lyrics.txt\n",
            "/content/rap/Deniro Farrar_lyrics.txt\n",
            "/content/rap/Common_lyrics.txt\n",
            "/content/rap/CunninLynguists_lyrics.txt\n",
            "/content/rap/Bas_lyrics.txt\n",
            "/content/rap/ASAP Ant_lyrics.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zhsgkuNi-Xy",
        "outputId": "8defda85-8198-4c48-c9f3-bebb957f4810"
      },
      "source": [
        "with open('/content/raplyrics.txt', 'r') as data:\r\n",
        "  dataset = [\"<|title|>\" + x.strip() for x in data.readlines()]\r\n",
        "\r\n",
        "train, eval = train_test_split(dataset, train_size=.9, random_state=2020)\r\n",
        "print(len(train))\r\n",
        "print(len(eval))\r\n",
        "\r\n",
        "with open('train_tmp.txt', 'w') as file_handle:\r\n",
        "  file_handle.write(\"<|endoftext|>\".join(train))\r\n",
        "\r\n",
        "with open('eval_tmp.txt', 'w') as file_handle:\r\n",
        "  file_handle.write(\"<|endoftext|>\".join(eval))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "167933\n",
            "18660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tSFZCFakawl"
      },
      "source": [
        "import os\r\n",
        "os.chdir(\"/content/transformers/examples/\")\r\n",
        "os.chdir(\"./language-modeling\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhDAThBekjIv",
        "outputId": "bdb699c3-6164-406c-ae66-e1f9e8bb7068"
      },
      "source": [
        "!python run_clm.py \\\r\n",
        "--model_type gpt2 \\\r\n",
        "--model_name_or_path gpt2 \\\r\n",
        "--train_file \"/content/train_tmp.txt\" \\\r\n",
        "--do_train \\\r\n",
        "--validation_file \"/content/eval_tmp.txt\" \\\r\n",
        "--do_eval \\\r\n",
        "--per_device_train_batch_size 1 \\\r\n",
        "--per_device_eval_batch_size 1 \\\r\n",
        "--save_steps -1 \\\r\n",
        "--num_train_epochs 5 \\\r\n",
        "--fp16 \\\r\n",
        "--output_dir=\"/content/model\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-28 18:30:50.920376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "02/28/2021 18:30:52 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "02/28/2021 18:30:52 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=/content/model, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=EvaluationStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Feb28_18-30-51_43334c911c08, logging_first_step=False, logging_steps=500, save_steps=-1, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/content/model, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=1)\n",
            "02/28/2021 18:30:52 - WARNING - datasets.builder -   Using custom data configuration default-5fa6c697fa0e52f4\n",
            "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-5fa6c697fa0e52f4/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691...\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-5fa6c697fa0e52f4/0.0.0/44d63bd03e7e554f16131765a251f2d8333a5fe8a73f6ea3de012dbc49443691. Subsequent calls will reuse this data.\n",
            "[INFO|file_utils.py:1302] 2021-02-28 18:30:52,379 >> https://huggingface.co/gpt2/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmps6zaxot1\n",
            "Downloading: 100% 665/665 [00:00<00:00, 1.01MB/s]\n",
            "[INFO|file_utils.py:1306] 2021-02-28 18:30:52,397 >> storing https://huggingface.co/gpt2/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|file_utils.py:1309] 2021-02-28 18:30:52,397 >> creating metadata file for /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:449] 2021-02-28 18:30:52,397 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:485] 2021-02-28 18:30:52,398 >> Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.3.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:449] 2021-02-28 18:30:52,414 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:485] 2021-02-28 18:30:52,415 >> Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.3.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1302] 2021-02-28 18:30:52,438 >> https://huggingface.co/gpt2/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpepv3jg61\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 24.3MB/s]\n",
            "[INFO|file_utils.py:1306] 2021-02-28 18:30:52,505 >> storing https://huggingface.co/gpt2/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|file_utils.py:1309] 2021-02-28 18:30:52,505 >> creating metadata file for /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|file_utils.py:1302] 2021-02-28 18:30:52,526 >> https://huggingface.co/gpt2/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmptc6k556z\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 21.4MB/s]\n",
            "[INFO|file_utils.py:1306] 2021-02-28 18:30:52,566 >> storing https://huggingface.co/gpt2/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|file_utils.py:1309] 2021-02-28 18:30:52,566 >> creating metadata file for /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|file_utils.py:1302] 2021-02-28 18:30:52,595 >> https://huggingface.co/gpt2/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpabzj6w7b\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 34.9MB/s]\n",
            "[INFO|file_utils.py:1306] 2021-02-28 18:30:52,665 >> storing https://huggingface.co/gpt2/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|file_utils.py:1309] 2021-02-28 18:30:52,665 >> creating metadata file for /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1786] 2021-02-28 18:30:52,666 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1786] 2021-02-28 18:30:52,666 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1786] 2021-02-28 18:30:52,666 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|file_utils.py:1302] 2021-02-28 18:30:52,742 >> https://huggingface.co/gpt2/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8qxazoto\n",
            "Downloading: 100% 548M/548M [00:17<00:00, 31.2MB/s]\n",
            "[INFO|file_utils.py:1306] 2021-02-28 18:31:10,434 >> storing https://huggingface.co/gpt2/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|file_utils.py:1309] 2021-02-28 18:31:10,434 >> creating metadata file for /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|modeling_utils.py:1027] 2021-02-28 18:31:10,435 >> loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|modeling_utils.py:1143] 2021-02-28 18:31:15,154 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1152] 2021-02-28 18:31:15,154 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[WARNING|tokenization_utils_base.py:3213] 2021-02-28 18:31:22,350 >> Token indices sequence length is longer than the specified maximum sequence length for this model (2688382 > 1024). Running this sequence through the model will result in indexing errors\n",
            "100% 1/1 [00:07<00:00,  7.26s/ba]\n",
            "100% 1/1 [00:00<00:00,  1.36ba/s]\n",
            "100% 1/1 [00:02<00:00,  2.17s/ba]\n",
            "100% 1/1 [00:00<00:00,  4.17ba/s]\n",
            "[INFO|trainer.py:432] 2021-02-28 18:31:49,815 >> The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: .\n",
            "[INFO|trainer.py:432] 2021-02-28 18:31:49,815 >> The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: .\n",
            "[INFO|trainer.py:348] 2021-02-28 18:31:49,816 >> Using amp fp16 backend\n",
            "[INFO|trainer.py:837] 2021-02-28 18:31:49,819 >> ***** Running training *****\n",
            "[INFO|trainer.py:838] 2021-02-28 18:31:49,819 >>   Num examples = 2625\n",
            "[INFO|trainer.py:839] 2021-02-28 18:31:49,819 >>   Num Epochs = 5\n",
            "[INFO|trainer.py:840] 2021-02-28 18:31:49,820 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:841] 2021-02-28 18:31:49,820 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:842] 2021-02-28 18:31:49,820 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:843] 2021-02-28 18:31:49,820 >>   Total optimization steps = 13125\n",
            "  0% 0/13125 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "{'loss': 2.9052, 'learning_rate': 4.80952380952381e-05, 'epoch': 0.19}\n",
            "{'loss': 2.7823, 'learning_rate': 4.6190476190476194e-05, 'epoch': 0.38}\n",
            "{'loss': 2.7309, 'learning_rate': 4.428571428571428e-05, 'epoch': 0.57}\n",
            "{'loss': 2.7066, 'learning_rate': 4.2380952380952385e-05, 'epoch': 0.76}\n",
            "{'loss': 2.6793, 'learning_rate': 4.047619047619048e-05, 'epoch': 0.95}\n",
            "{'loss': 2.5921, 'learning_rate': 3.857142857142858e-05, 'epoch': 1.14}\n",
            "{'loss': 2.5609, 'learning_rate': 3.6666666666666666e-05, 'epoch': 1.33}\n",
            "{'loss': 2.5525, 'learning_rate': 3.476190476190476e-05, 'epoch': 1.52}\n",
            "{'loss': 2.5579, 'learning_rate': 3.285714285714286e-05, 'epoch': 1.71}\n",
            "{'loss': 2.5447, 'learning_rate': 3.095238095238095e-05, 'epoch': 1.9}\n",
            "{'loss': 2.4978, 'learning_rate': 2.9047619047619052e-05, 'epoch': 2.1}\n",
            "{'loss': 2.4587, 'learning_rate': 2.714285714285714e-05, 'epoch': 2.29}\n",
            "{'loss': 2.4624, 'learning_rate': 2.523809523809524e-05, 'epoch': 2.48}\n",
            "{'loss': 2.4577, 'learning_rate': 2.3333333333333336e-05, 'epoch': 2.67}\n",
            "{'loss': 2.4534, 'learning_rate': 2.1428571428571428e-05, 'epoch': 2.86}\n",
            "{'loss': 2.4341, 'learning_rate': 1.9523809523809524e-05, 'epoch': 3.05}\n",
            "{'loss': 2.3926, 'learning_rate': 1.761904761904762e-05, 'epoch': 3.24}\n",
            "{'loss': 2.3891, 'learning_rate': 1.5714285714285715e-05, 'epoch': 3.43}\n",
            "{'loss': 2.3999, 'learning_rate': 1.3809523809523811e-05, 'epoch': 3.62}\n",
            "{'loss': 2.3954, 'learning_rate': 1.1904761904761905e-05, 'epoch': 3.81}\n",
            "{'loss': 2.3932, 'learning_rate': 1e-05, 'epoch': 4.0}\n",
            "{'loss': 2.3519, 'learning_rate': 8.095238095238097e-06, 'epoch': 4.19}\n",
            "{'loss': 2.3553, 'learning_rate': 6.190476190476191e-06, 'epoch': 4.38}\n",
            "{'loss': 2.3511, 'learning_rate': 4.285714285714286e-06, 'epoch': 4.57}\n",
            "{'loss': 2.358, 'learning_rate': 2.3809523809523808e-06, 'epoch': 4.76}\n",
            "{'loss': 2.3503, 'learning_rate': 4.761904761904763e-07, 'epoch': 4.95}\n",
            "100% 13125/13125 [1:02:12<00:00,  3.52it/s][INFO|trainer.py:1007] 2021-02-28 19:34:02,788 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 3732.9688, 'train_samples_per_second': 3.516, 'epoch': 5.0}\n",
            "100% 13125/13125 [1:02:12<00:00,  3.52it/s]\n",
            "[INFO|trainer.py:1408] 2021-02-28 19:34:02,810 >> Saving model checkpoint to /content/model\n",
            "[INFO|configuration_utils.py:304] 2021-02-28 19:34:02,813 >> Configuration saved in /content/model/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-02-28 19:34:04,497 >> Model weights saved in /content/model/pytorch_model.bin\n",
            "Traceback (most recent call last):\n",
            "  File \"run_clm.py\", line 406, in <module>\n",
            "    main()\n",
            "  File \"run_clm.py\", line 380, in main\n",
            "    trainer.log_metrics(\"train\", metrics)\n",
            "AttributeError: 'Trainer' object has no attribute 'log_metrics'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BId0zahlwyb"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}